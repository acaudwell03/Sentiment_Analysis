{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76aa22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- IMPORTS ---------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from datasets import load_dataset\n",
    "from classes import *\n",
    "from CNN import CNN\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "596d1f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- CONFIGURATION ---------\n",
    "DATASET_NAME = 'go_emotions'\n",
    "DATASET_CONFIG = 'simplified'\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available()\n",
    "                      else \"cuda\" if torch.cuda.is_available()\n",
    "                      else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "PREPROCESSOR = TextPreprocessor(extra_stopwords={'name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa0b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docstrings generated from Anysphere. (2025). Cursor [Large language model]. https://cursor.com/en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab8e4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- DATA PREPARATION ---------\n",
    "def prepare_dataset_arrays():\n",
    "    \"\"\"Load GoEmotions, drop neutral-only samples, and return arrays per split.\n",
    "\n",
    "    Removes the \"neutral\" label from multi-label annotations, filters examples\n",
    "    that would otherwise have no labels, and returns raw texts plus binarized\n",
    "    label arrays for train/validation/test, along with the remaining label names.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], np.ndarray, List[str], np.ndarray, List[str], np.ndarray, List[str]]:\n",
    "            `(X_train, y_train, X_val, y_val, X_test, y_test, new_labels)` where\n",
    "            each `X_*` is a list of raw strings and each `y_*` is a multi-hot\n",
    "            numpy array aligned to `new_labels`.\n",
    "    \"\"\"\n",
    "    ds = load_dataset(DATASET_NAME, DATASET_CONFIG)\n",
    "\n",
    "    label_names = ds[\"train\"].features[\"labels\"].feature.names\n",
    "    neutral_idx = label_names.index(\"neutral\")\n",
    "    new_labels = [name for name in label_names if name != \"neutral\"]\n",
    "\n",
    "    def not_neutral_only(ex):\n",
    "        return not (len(ex[\"labels\"]) == 1 and ex[\"labels\"][0] == neutral_idx)\n",
    "\n",
    "    def remove_neutral(ex):\n",
    "        ex[\"labels\"] = [l for l in ex[\"labels\"] if l != neutral_idx]\n",
    "        return ex\n",
    "\n",
    "    for split in [\"train\", \"validation\", \"test\"]:\n",
    "        ds[split] = ds[split].filter(not_neutral_only).map(remove_neutral)\n",
    "\n",
    "    mlb = MultiLabelBinarizer(classes=range(len(new_labels)))\n",
    "    mlb.fit(ds[\"train\"][\"labels\"])\n",
    "\n",
    "    def to_arrays(split):\n",
    "        X = ds[split][\"text\"]\n",
    "        y = mlb.transform(ds[split][\"labels\"])\n",
    "        return X, y\n",
    "\n",
    "    return (\n",
    "        *to_arrays(\"train\"),\n",
    "        *to_arrays(\"validation\"),\n",
    "        *to_arrays(\"test\"),\n",
    "        new_labels\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33cd7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"Clean texts, build vocabulary, and return encoded Torch datasets.\n",
    "\n",
    "    Steps:\n",
    "    - Apply `PREPROCESSOR.preprocess` to each text in train/val/test.\n",
    "    - Remove empty strings and align labels accordingly.\n",
    "    - Build vocabulary on cleaned training texts only.\n",
    "    - Encode all splits to padded id sequences and wrap in `TextDataset`.\n",
    "\n",
    "    Args:\n",
    "        X_train, X_val, X_test (List[str]): Raw texts per split.\n",
    "        y_train, y_val, y_test (array-like): Multi-hot label arrays aligned to texts.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[TextDataset, TextDataset, TextDataset, int]: Encoded datasets and `vocab_size`.\n",
    "    \"\"\"\n",
    "    # Preprocess texts\n",
    "    X_train = [PREPROCESSOR.preprocess(text) for text in X_train]\n",
    "    X_val = [PREPROCESSOR.preprocess(text) for text in X_val]\n",
    "    X_test = [PREPROCESSOR.preprocess(text) for text in X_test]\n",
    "\n",
    "    # Remove empty texts\n",
    "    def clean_texts(texts, labels):\n",
    "        cleaned_X, cleaned_y = [], []\n",
    "        for text, label in zip(texts, labels):\n",
    "            if text.strip():\n",
    "                cleaned_X.append(text)\n",
    "                cleaned_y.append(label)\n",
    "        return cleaned_X, cleaned_y\n",
    "\n",
    "    X_train, y_train = clean_texts(X_train, y_train)\n",
    "    X_val, y_val = clean_texts(X_val, y_val)\n",
    "    X_test, y_test = clean_texts(X_test, y_test)\n",
    "\n",
    "    # Build vocabulary on training data\n",
    "    PREPROCESSOR.build_vocab(X_train)\n",
    "    vocab_size = len(PREPROCESSOR.word2idx)\n",
    "\n",
    "    # Encode datasets\n",
    "    X_train = PREPROCESSOR.encode_batch(X_train)\n",
    "    X_val = PREPROCESSOR.encode_batch(X_val)\n",
    "    X_test = PREPROCESSOR.encode_batch(X_test)\n",
    "\n",
    "    # Create dataset objects\n",
    "    return (\n",
    "        TextDataset(X_train, y_train),\n",
    "        TextDataset(X_val, y_val),\n",
    "        TextDataset(X_test, y_test),\n",
    "        vocab_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22981741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_loaders(train_dataset, val_dataset, test_dataset):\n",
    "    \"\"\"Create DataLoader objects for training, validation, and test splits.\n",
    "\n",
    "    Args:\n",
    "        train_dataset, val_dataset, test_dataset (TextDataset): Encoded datasets.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DataLoader, DataLoader, DataLoader]: DataLoaders with `BATCH_SIZE`.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True),\n",
    "        DataLoader(val_dataset, batch_size=BATCH_SIZE),\n",
    "        DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18d67625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pos_weight(y_train):\n",
    "    \"\"\"Compute normalized positive class weights for BCEWithLogitsLoss.\n",
    "\n",
    "    Uses per-class ratio of negatives to positives, capped to avoid extremes,\n",
    "    then normalizes by the mean to keep magnitudes stable.\n",
    "\n",
    "    Args:\n",
    "        y_train (array-like): Multi-hot labels for the training split.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Vector of shape `(num_classes,)` with normalized weights.\n",
    "    \"\"\"\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    N, C = y_train_tensor.shape\n",
    "    pos_counts = y_train_tensor.sum(dim=0)\n",
    "    neg_counts = N - pos_counts\n",
    "    pos_weight = (neg_counts / pos_counts.clamp(min=1)).clamp(max=5.0)\n",
    "    return pos_weight / pos_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef77d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_thresholds(probs, targets, low=0.1, high=0.9, steps=81):\n",
    "    \"\"\"Grid-search per-class thresholds to maximize micro-F1 per label.\n",
    "\n",
    "    Args:\n",
    "        probs (np.ndarray): Predicted probabilities, shape `(N, C)`.\n",
    "        targets (np.ndarray): Binary ground-truth array, shape `(N, C)`.\n",
    "        low (float): Lower bound for threshold sweep (inclusive).\n",
    "        high (float): Upper bound for threshold sweep (inclusive).\n",
    "        steps (int): Number of thresholds to evaluate between `low` and `high`.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Best threshold per class, shape `(C,)`.\n",
    "    \"\"\"\n",
    "    C = probs.shape[1]\n",
    "    best_thresholds = np.full(C, 0.5)\n",
    "    for i in range(C):\n",
    "        best_f1 = 0.0\n",
    "        for t in np.linspace(low, high, steps):\n",
    "            pred_i = (probs[:, i] >= t).astype(int)\n",
    "            f1_i = f1_score(targets[:, i], pred_i, zero_division=0)\n",
    "            if f1_i > best_f1:\n",
    "                best_f1 = f1_i\n",
    "                best_thresholds[i] = t\n",
    "    return best_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f54f5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_thresholds(trainer, val_loader, test_loader, labels, save_csv=True):\n",
    "    \"\"\"Tune decision thresholds on validation, evaluate on both val/test.\n",
    "\n",
    "    Args:\n",
    "        trainer (MyCnnFunctions): Provides `evaluate` to get probabilities/labels.\n",
    "        val_loader, test_loader (DataLoader): Validation and test splits.\n",
    "        labels (List[str]): Human-readable label names for reports/CSVs.\n",
    "        save_csv (bool): If True, saves per-label F1 tables to CSV files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, pd.DataFrame, pd.DataFrame]: `(thresholds, val_df, test_df)`.\n",
    "    \"\"\"\n",
    "    # Tune on validation\n",
    "    probs_val, targets_val = trainer.evaluate(val_loader)\n",
    "    best_thresholds = tune_thresholds(probs_val, targets_val)\n",
    "    preds_val = (probs_val >= best_thresholds[None, :]).astype(int)\n",
    "\n",
    "    print(\"\\n=== Validation Set ===\")\n",
    "    print(classification_report(targets_val, preds_val,\n",
    "          zero_division=0, target_names=labels))\n",
    "    f1_df_val = pd.DataFrame({'Label': labels, 'F1-score': f1_score(\n",
    "        targets_val, preds_val, average=None, zero_division=0).round(2)})\n",
    "    if save_csv:\n",
    "        f1_df_val.to_csv('val_metrics.csv', index=False)\n",
    "\n",
    "    # Apply to test\n",
    "    probs_test, targets_test = trainer.evaluate(test_loader)\n",
    "    preds_test = (probs_test >= best_thresholds[None, :]).astype(int)\n",
    "\n",
    "    print(\"\\n=== Test Set ===\")\n",
    "    print(classification_report(targets_test, preds_test,\n",
    "          zero_division=0, target_names=labels))\n",
    "    f1_df_test = pd.DataFrame({'Label': labels, 'F1-score': f1_score(\n",
    "        targets_test, preds_test, average=None, zero_division=0).round(2)})\n",
    "    if save_csv:\n",
    "        f1_df_test.to_csv('cnn_metrics.csv', index=False)\n",
    "\n",
    "    return best_thresholds, f1_df_val, f1_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "787b9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- TRAINING & TUNING ---------\n",
    "def train_and_tune_model(vocab_size, labels, norm_weight, train_loader, val_loader, test_loader):\n",
    "    \"\"\"Optimize hyperparameters, train final model, and plot results.\n",
    "\n",
    "    Runs an Optuna study to tune architecture and training hyperparameters, then\n",
    "    retrains a final model on the best configuration and evaluates it.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the token vocabulary.\n",
    "        labels (List[str]): Label names for reporting and head size.\n",
    "        norm_weight (torch.Tensor): Normalized positive class weights.\n",
    "        train_loader, val_loader, test_loader (DataLoader): Data splits.\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        embed_dim = trial.suggest_int('embed_dim', 50, 300)\n",
    "        dropout = trial.suggest_float('dropout', 0.2, 0.7)\n",
    "        lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "        weight_decay = trial.suggest_float(\n",
    "            'weight_decay', 1e-5, 1e-2, log=True)\n",
    "        num_filter = trial.suggest_int('num_filter', 8, 256)\n",
    "        fc1_size = trial.suggest_categorical(\"fc1_size\", [64, 128, 256])\n",
    "        alpha = trial.suggest_float(\"weight_scale\", 0.25, 2.0)\n",
    "\n",
    "        model = CNN(vocab_size, embed_dim, len(labels), num_filter,\n",
    "                    dropout, fc1_size=fc1_size).to(DEVICE)\n",
    "        optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scaled = torch.clamp(norm_weight * alpha, max=5.0).to(DEVICE)\n",
    "        loss_func = nn.BCEWithLogitsLoss(pos_weight=scaled)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "        trainer = MyCnnFunctions(model, DEVICE, multi_label=True)\n",
    "\n",
    "        result = trainer.model_trainer(epochs=5, train_loader=train_loader, val_loader=val_loader,\n",
    "                                       loss_func=loss_func, optimizer=optimizer, scheduler=scheduler, patience=2)\n",
    "        return float(result[\"best_val_f1\"])\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=30)\n",
    "    best_params = study.best_params\n",
    "    print(\"Best parameters:\", best_params)\n",
    "\n",
    "    # Final training\n",
    "    model = CNN(vocab_size, best_params['embed_dim'], len(labels),\n",
    "                best_params['num_filter'], best_params['dropout'], fc1_size=best_params['fc1_size']).to(DEVICE)\n",
    "    optimizer = Adam(model.parameters(\n",
    "    ), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n",
    "    scaled = torch.clamp(\n",
    "        norm_weight * best_params['weight_scale'], max=5.0).to(DEVICE)\n",
    "    loss_func = nn.BCEWithLogitsLoss(pos_weight=scaled)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    trainer = MyCnnFunctions(model, DEVICE, multi_label=True)\n",
    "\n",
    "    result = trainer.model_trainer(epochs=50, train_loader=train_loader, val_loader=val_loader,\n",
    "                                   loss_func=loss_func, optimizer=optimizer, scheduler=scheduler, patience=2)\n",
    "\n",
    "    torch.save(model.state_dict(), \"cnn_model.pth\")\n",
    "    print(\"Model saved to cnn_model.pth\")\n",
    "\n",
    "    # Evaluate\n",
    "    best_thresholds, f1_df_val, f1_df_test = evaluate_with_thresholds(\n",
    "        trainer, val_loader, test_loader, labels)\n",
    "    print(f'BEST THRESHOLDS: {best_thresholds}')\n",
    "    trainer.plot_training(result[\"train_losses\"], result[\"val_losses\"],\n",
    "                          result[\"train_accuracies\"], result[\"val_f1s\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e196018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- MAIN ---------\n",
    "def main():\n",
    "    \"\"\"Execute the complete CNN-based emotion classification pipeline with hyperparameter optimization.\n",
    "\n",
    "    Orchestrates the entire deep learning pipeline for multi-label emotion classification:\n",
    "    1. Dataset preparation: Load GoEmotions, remove neutral labels, create arrays\n",
    "    2. Data preprocessing: Clean texts, build vocabulary, encode to tensors\n",
    "    3. Data loader creation: Set up PyTorch DataLoaders for training/validation/test\n",
    "    4. Class weight computation: Calculate balanced weights for imbalanced classes\n",
    "    5. Model training and tuning: Use Optuna for hyperparameter optimization\n",
    "    6. Evaluation: Apply optimal thresholds and generate comprehensive metrics\n",
    "    7. Visualization: Plot training curves and save results\n",
    "\n",
    "    The pipeline uses a CNN architecture with word embeddings, convolutional layers,\n",
    "    and fully connected layers for multi-label emotion classification on the GoEmotions\n",
    "    dataset. It includes automatic hyperparameter tuning and threshold optimization\n",
    "    for optimal F1 scores.\n",
    "\n",
    "    Outputs:\n",
    "        - Saves trained model to 'cnn_model.pth'\n",
    "        - Saves validation metrics to 'val_metrics.csv'\n",
    "        - Saves test metrics to 'test_metrics.csv'\n",
    "        - Displays training plots and classification reports\n",
    "        - Prints optimal thresholds for each emotion class\n",
    "\n",
    "    Configuration:\n",
    "        Uses global constants: DATASET_NAME, DATASET_CONFIG, DEVICE, BATCH_SIZE, PREPROCESSOR\n",
    "\n",
    "    Returns:\n",
    "        None: Executes the complete pipeline and saves all results\n",
    "    \"\"\"\n",
    "    print('---PREPARING DATASETS---')\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, labels = prepare_dataset_arrays()\n",
    "    print('---DONE---')\n",
    "    print('---PREPROCESSING DATA---')\n",
    "    train_dataset, val_dataset, test_dataset, vocab_size = preprocess_data(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    train_loader, val_loader, test_loader = prepare_data_loaders(\n",
    "        train_dataset, val_dataset, test_dataset)\n",
    "    pos_weight = compute_pos_weight(y_train)\n",
    "    print('---DONE---')\n",
    "    print('---TRAINING, TUNING, AND EVALUATING MODEL---')\n",
    "    train_and_tune_model(vocab_size, labels, pos_weight,\n",
    "                         train_loader, val_loader, test_loader)\n",
    "    print('---DONE---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89eee8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---PREPARING DATASETS---\n",
      "---DONE---\n",
      "---PREPROCESSING DATA---\n",
      "---DONE---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('---PREPARING DATASETS---')\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, labels = prepare_dataset_arrays()\n",
    "    print('---DONE---')\n",
    "    print('---PREPROCESSING DATA---')\n",
    "    train_dataset, val_dataset, test_dataset, vocab_size = preprocess_data(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    train_loader, val_loader, test_loader = prepare_data_loaders(\n",
    "        train_dataset, val_dataset, test_dataset)\n",
    "    pos_weight = compute_pos_weight(y_train)\n",
    "    print('---DONE---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48bee3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer(classes=range(0, 27))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultiLabelBinarizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html\">?<span>Documentation for MultiLabelBinarizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultiLabelBinarizer(classes=range(0, 27))</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultiLabelBinarizer(classes=range(0, 27))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer(classes=range(len(labels)))\n",
    "mlb.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164dc1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.56, 0.34, 0.4, 0.24, 0.26, 0.19, 0.38, 0.36, 0.26, 0.27, 0.27, 0.41, 0.24, 0.25,\n",
    "              0.54, 0.79, 0.5,  0.31, 0.62, 0.5,  0.39, 0.1,  0.34, 0.1,  0.12, 0.43, 0.53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ae360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   | Train Loss: 0.2073 | Train Acc: 0.9616 | Val Loss: 0.1788 | Val Micro F1: 0.4413 | Wait: 0\n",
      "Epoch 1   | Train Loss: 0.1709 | Train Acc: 0.9644 | Val Loss: 0.1627 | Val Micro F1: 0.5018 | Wait: 0\n",
      "Epoch 2   | Train Loss: 0.1578 | Train Acc: 0.9653 | Val Loss: 0.1567 | Val Micro F1: 0.5327 | Wait: 0\n",
      "Epoch 3   | Train Loss: 0.1532 | Train Acc: 0.9655 | Val Loss: 0.1542 | Val Micro F1: 0.5392 | Wait: 0\n",
      "Epoch 4   | Train Loss: 0.1501 | Train Acc: 0.9656 | Val Loss: 0.1524 | Val Micro F1: 0.5371 | Wait: 1\n",
      "Epoch 5   | Train Loss: 0.1472 | Train Acc: 0.9659 | Val Loss: 0.1522 | Val Micro F1: 0.5337 | Wait: 2\n",
      "Early stopping at epoch 5\n",
      "Model saved to cnn_model.pth\n"
     ]
    }
   ],
   "source": [
    "model = CNN(vocab_size, 169, len(labels),\n",
    "            131, 0.274, fc1_size=256).to(DEVICE)\n",
    "optimizer = Adam(model.parameters(\n",
    "), lr=1.319e-3, weight_decay=5.256e-5)\n",
    "scaled = torch.clamp(\n",
    "    pos_weight * 1.779, max=5.0).to(DEVICE)\n",
    "loss_func = nn.BCEWithLogitsLoss(pos_weight=scaled)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "trainer = MyCnnFunctions(model, DEVICE, multi_label=True)\n",
    "\n",
    "result = trainer.model_trainer(epochs=50, train_loader=train_loader, val_loader=val_loader,\n",
    "                               loss_func=loss_func, optimizer=optimizer, scheduler=scheduler, patience=2)\n",
    "\n",
    "torch.save(model.state_dict(), \"cnn_model.pth\")\n",
    "print(\"Model saved to cnn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc62b7b1",
   "metadata": {},
   "source": [
    "# Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e65e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cnn(texts):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    X = PREPROCESSOR.encode_batch(texts)\n",
    "    device = next(model.parameters()).device  # Get model device\n",
    "    X = X.to(device)\n",
    "\n",
    "    # Pad sequences to at least the largest kernel size\n",
    "    min_len = max([conv.kernel_size[0] for conv in model.convs])\n",
    "    if X.size(1) < min_len:\n",
    "        pad_size = min_len - X.size(1)\n",
    "        X = F.pad(X, (0, pad_size))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "    if thresholds is not None:\n",
    "        preds = (probs >= thresholds).astype(int)\n",
    "    else:\n",
    "        preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    # Convert back to labels\n",
    "    labels = mlb.inverse_transform(preds)[0]\n",
    "    print(f\"Text: {texts}\")\n",
    "    print(f\"Labels: {[label_names[l] for l in labels]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input(str(\"Enter:\"))\n",
    "\n",
    "predict_cnn(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
